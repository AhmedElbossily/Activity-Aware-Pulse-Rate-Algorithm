{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "\n",
    "import scipy.signal\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], [] \n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "  \n",
    "    # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def BandPassFilter(data, lowcut= 0.67, highcut =5, fs=125, order=5):\n",
    "    \"\"\"\n",
    "    Create a bandpass filter\n",
    "\n",
    "    Args:\n",
    "        data: a numpy array of the signal needed to be filtered.\n",
    "        lowcut: low cut off frequency.\n",
    "        highcut: high cut off frequency.\n",
    "        fs: sampling rate\n",
    "        order: The order of the filter\n",
    "\n",
    "    Returns:\n",
    "        filtered signal\n",
    "    \"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_bandpass(lowcut=0.67, highcut=5, fs=125, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def FreqVarification(Nprev, Ncrrent):\n",
    "    \"\"\"\n",
    "    Varify that the heart rate between to successive time frames does not exceed 11 BPM\n",
    "\n",
    "    Args:\n",
    "        Nprev: the index of the dominant previous time frame PPG frequency in the signal frequency NumPy array.\n",
    "        Nprev: the index of the dominant current time frame PPG frequency in the frequency NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        The index of the dominant current time frame PPG frequency after the varification\n",
    "    \"\"\"\n",
    "    # maximum difference indexes between two dominant frequences in two successive frames\n",
    "    ceta = 6\n",
    "    # value used to increase or decrease the index of the current dominant frequency if it exceeds 11 BPM\n",
    "    taw = 2\n",
    "\n",
    "    if Ncrrent - Nprev >= ceta:\n",
    "        return Nprev +taw\n",
    "    if Ncrrent - Nprev <= -1 * ceta:\n",
    "        return Nprev - taw\n",
    "    return Ncrrent\n",
    "\n",
    "def GenerateFramesForData (data, ref, fs, window_length_s, window_shift_s):\n",
    "\n",
    "    \"\"\"\n",
    "    Splits the signals into 8 seconds frames with 2 seconds shift between them and filters it \n",
    "\n",
    "    Args:\n",
    "        data: NumPy array of all signals in a file.\n",
    "        ref: NumPy array of the true heart rate value for every 8 seconds.\n",
    "        fs: sampling rate\n",
    "        window_length_s: Window length in seconds \n",
    "        window_shift_s: shift between windows in seconds\n",
    "\n",
    "    Returns:\n",
    "        features: NumPy array has all filtered signals in frames\n",
    "        labels: NumPy array for the heart rate for the corresponding frame in the feature array\n",
    "    \"\"\"\n",
    "    window_length = window_length_s * fs\n",
    "    window_shift = window_shift_s * fs\n",
    "    labels, subjects, activities, features = [],[],[],[]\n",
    "    \n",
    "    # variable for storing number of frames in the file \n",
    "    k= 0\n",
    "    # genetating frames\n",
    "    for i in range (0, len(data[0])-window_length, window_shift):\n",
    "        window = range (i, i+window_length)\n",
    "        #ECG = data[0][window]\n",
    "        #ECG = BandPassFilter(ECG)\n",
    "\n",
    "        #PPG_1 = data[1][window]\n",
    "        #PPG_2 = data[2][window]\n",
    "        PPG = data[0][window]\n",
    "        PPG = BandPassFilter(PPG)\n",
    "\n",
    "        x = data[1][window]\n",
    "        x = BandPassFilter(x)\n",
    "\n",
    "        y = data[2][window]\n",
    "        y = BandPassFilter(y)\n",
    "\n",
    "        z = data[3][window]\n",
    "        z = BandPassFilter(z)\n",
    "\n",
    "        # Calculate the magnitude acceleration\n",
    "        magAcc = np.sum(np.square(np.vstack((x,y,z))), axis= 0)\n",
    "        magAcc = BandPassFilter(magAcc)\n",
    "        features.append(( PPG, x, y, z, magAcc))\n",
    "        k +=1\n",
    "\n",
    "    labels = ref[0:k]\n",
    "    features = np.array(features)\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "def getFirstDomFreq(features,label, fs=125):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the dominant frequency in the first time frame.\n",
    "\n",
    "    Args:\n",
    "        features: NumPy array has all filtered signals in frames\n",
    "        labels: NumPy array for the heart rate for the corresponding frame in the feature array\n",
    "        fs: sampling rate\n",
    "\n",
    "    Returns:\n",
    "        the dominant frequency of the first frame for every subject\n",
    "        \n",
    "    \"\"\"\n",
    "    # get the desired features \n",
    "    PPG = features[0]\n",
    "    \n",
    "    # FFT\n",
    "    fft_len = max(len(PPG),4096)\n",
    "    fftFreqs = np.fft.rfftfreq(fft_len, 1/fs)\n",
    "    fft_PPG = np.abs(np.fft.rfft(PPG, fft_len))\n",
    "    \n",
    "    #Calculate dominate freqs\n",
    "    freqs = fftFreqs[(fftFreqs>0.67)&(fftFreqs<5)]\n",
    "    dominantFreq_PPG = freqs[np.argmax(fft_PPG[(fftFreqs>0.67)&(fftFreqs<5)])]\n",
    "\n",
    "    # get the fundamintal frequency if the dominant frequency is equal to the first harmonic frequency.\n",
    "    # the first harmonic frequency will be bigger that 140 BPM (2.345 HZ)\n",
    "    firstHarmonicCheckValue =  2.345\n",
    "    if  dominantFreq_PPG > firstHarmonicCheckValue:\n",
    "       \n",
    "        return dominantFreq_PPG/2\n",
    "      \n",
    "    return dominantFreq_PPG\n",
    "\n",
    "def getErrorConfidancePerwindonw(features,label, prev_dominantFreq_PPG, fs=125):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate absolute error of the heart rate for every frame and its confidance value.\n",
    "\n",
    "    Args:\n",
    "        features: NumPy array has all filtered signals in frames\n",
    "        labels: NumPy array for the heart rate for the corresponding frame in the feature array\n",
    "        fs: sampling rate\n",
    "\n",
    "    Returns:\n",
    "        the dominant frequency of the first frame for every subject\n",
    "        absError: the absolute error of heart beat rate for every frame\n",
    "        confidence: value that represents how the algorithm confidant on heat rate estimate\n",
    "        dominantFreq_PPG: the dominant frequency of the current frame        \n",
    "    \"\"\"\n",
    "\n",
    "    # get the desired features \n",
    "    PPG = features[0]\n",
    "    X = features[1]\n",
    "    Y = features[2]\n",
    "    Z = features[3]\n",
    "    mag = features[4]\n",
    "\n",
    "    # FFT\n",
    "    fft_len = max(len(PPG),4096)\n",
    "    fftFreqs = np.fft.rfftfreq(fft_len, 1/fs)\n",
    "    freqs = fftFreqs[(fftFreqs>0.67)&(fftFreqs<5)]\n",
    "\n",
    "    fft_PPG = np.abs(np.fft.rfft(PPG, fft_len))\n",
    "    fft_X = np.abs(np.fft.rfft(X, fft_len))\n",
    "    fft_Y = np.abs(np.fft.rfft(Y, fft_len))\n",
    "    fft_Z = np.abs(np.fft.rfft(Z, fft_len))\n",
    "    fft_mag = np.abs(np.fft.rfft(mag, fft_len))\n",
    "\n",
    "    fft_X_wind = fft_X[(fftFreqs>0.67)&(fftFreqs<5)]\n",
    "    fft_Y_wind = fft_Y[(fftFreqs>0.67)&(fftFreqs<5)]\n",
    "    fft_Z_wind = fft_Z[(fftFreqs>0.67)&(fftFreqs<5)] \n",
    "    fft_mag_wind = fft_mag[(fftFreqs>0.67)&(fftFreqs<5)]\n",
    "\n",
    "    # Calculate the dominant frequences for x acceleration\n",
    "    threshold_X = 0.5* np.max(fft_X_wind)\n",
    "    F_dominant_X = freqs[fft_X_wind > threshold_X]\n",
    "    M_dominant_X = fft_X_wind [fft_X_wind > threshold_X]\n",
    "\n",
    "    # Calculate the dominant frequences for y acceleration\n",
    "    threshold_Y = 0.5* np.max(fft_Y_wind)\n",
    "    F_dominant_Y = freqs[fft_Y_wind > threshold_Y]\n",
    "    M_dominant_Y = fft_Y_wind [fft_Y_wind > threshold_Y]\n",
    "\n",
    "    # Calculate the dominant frequences for z acceleration    \n",
    "    threshold_Z = 0.5* np.max(fft_Z_wind)\n",
    "    F_dominant_Z = freqs[fft_Z_wind > threshold_Z]\n",
    "    M_dominant_Z = fft_Z_wind [fft_Z_wind > threshold_Z]\n",
    "    \n",
    "    # Calculate the dominant frequences for mag acceleration    \n",
    "    threshold_mag = 0.5* np.max(fft_mag_wind)\n",
    "    F_dominant_mag = freqs[fft_mag_wind > threshold_mag]\n",
    "    M_dominant_mag = fft_mag_wind [fft_mag_wind > threshold_mag]\n",
    "\n",
    "    # form one array for all dominant acceleration of all channels\n",
    "    dominant_ACC = np.append(F_dominant_X, F_dominant_Y) \n",
    "    dominant_ACC = np.append(dominant_ACC, F_dominant_Z)\n",
    "    dominant_ACC = np.append(dominant_ACC, F_dominant_mag)\n",
    "    dominant_ACC = np.unique(dominant_ACC)\n",
    "    \n",
    "\n",
    "    # Remove frequences in dominant_ACC array that equal to the \n",
    "    # previous heart rate dominant frequences +-0.2 HZ\n",
    "    prev_freq_tolerance = 0.2\n",
    "    for d in dominant_ACC:\n",
    "        if d > prev_dominantFreq_PPG - prev_freq_tolerance and d < prev_dominantFreq_PPG + prev_freq_tolerance:\n",
    "            dominant_ACC = np.delete(dominant_ACC, np.argwhere(dominant_ACC == d))\n",
    "\n",
    "    # Filter signal with in 40 to 240 BPM by removing the acceleration dominant frequences from it \n",
    "    for f in fftFreqs:\n",
    "        if f in dominant_ACC:\n",
    "            fft_PPG[np.argwhere(fftFreqs==f)] = 0.0   \n",
    "  \n",
    "    \n",
    "    #Calculate dominate freqs\n",
    "    dominantFreq_PPG = freqs[np.argmax(fft_PPG[(fftFreqs>0.67)&(fftFreqs<5)])]\n",
    "\n",
    "    # varify that the heart rate difference between two successive frames not more than 11 BPM    \n",
    "    indx_dominantFreq_PPG = FreqVarification(np.argwhere(freqs==prev_dominantFreq_PPG), np.argwhere(freqs==dominantFreq_PPG))\n",
    "\n",
    "    dominantFreq_PPG = freqs[indx_dominantFreq_PPG][0][0]\n",
    "\n",
    "   \n",
    "    # calculate the energy around the expexted frequency (Confidance)\n",
    "    spectral_energy_PPG = (fft_PPG)\n",
    "    band_around_dominant_freq = 0.15\n",
    "    dom_wind = (fftFreqs>(dominantFreq_PPG- band_around_dominant_freq)) & (fftFreqs< (dominantFreq_PPG+ band_around_dominant_freq))\n",
    "    \n",
    "    confidence = np.sum(spectral_energy_PPG[dom_wind])/np.sum(spectral_energy_PPG)\n",
    "\n",
    "    absError = abs ((dominantFreq_PPG*60)- label)\n",
    "    \n",
    "    return absError, confidence, dominantFreq_PPG\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    # Load data using scipy. \"scipy.io.loadmat(f)\"\n",
    "\n",
    "    data = LoadTroikaDataFile(data_fl)\n",
    "    ref = scipy.io.loadmat(ref_fl).get('BPM0')\n",
    "    features, labels = GenerateFramesForData(data, ref, 125, 8, 2)\n",
    "\n",
    "    absErrorS = []\n",
    "    ConfidanceS = []\n",
    "    dominantFreq_PPG = getFirstDomFreq(features[0], labels[0])\n",
    "    imageIndx = 0\n",
    "    for (f, l) in zip(features, labels):\n",
    "        absError, confidence, dominantFreq_PPG = getErrorConfidancePerwindonw(f, l,dominantFreq_PPG)\n",
    "        absErrorS = np.append(absErrorS, absError)\n",
    "        ConfidanceS = np.append(ConfidanceS, confidence)\n",
    "        imageIndx +=1\n",
    "        \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "\n",
    "    # Return per-estimate absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    return absErrorS, ConfidanceS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8336051962800388"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - ### **To run this code** \n",
    "    - You need to import\n",
    "        - [glob](https://docs.python.org/3/library/glob.html)\n",
    "        - [numpy](https://numpy.org/)\n",
    "        - [scipy](https://www.scipy.org/)\n",
    "        - collections\n",
    "        - matplotlib\n",
    "    - The notebook consists of two main code cells. \n",
    "    - The first cell contains all the algorithm functions. \n",
    "    - The second one contains the Evaluate method which kicks off the algorithm.\n",
    "     \n",
    "> - ### **Data Description** \n",
    "Dataset Troika[1] was used to build the algorithm. You can find the dataset under datasets/troika/training_data. \n",
    "    - What activities were performed in the dataset.\n",
    "        - The dataset contains (ECG signal, PPG signal, (x,y,z) accelerattion signal) \n",
    "        - The ground truth of the hear beat was obtained from the ECG signal\n",
    "        - The magnitude acceleration was obtained from (x,y,z) acceleration signals\n",
    "        - All signals are filtered by a band bass filter 40:240 BPM\n",
    "    - Features of the sensor that was used.\n",
    "        - PPG, (x,y,z) accelerattion.  \n",
    "    - The quantity of data in the dataset.\n",
    "        - The dataset consists of 24 files.\n",
    "        - Files with similar name \"DATA_01_TYPE01\" contain a variable 'sig'. It ehas 6 rows. The first row is a simultaneous recording of ECG. The second row and the third row are two channels of PPG. The last three rows are simultaneous recordings of acceleration data (in x-, y-, and z-axis).\n",
    "        - Files with a similar name \"REF_01_TYPE01\" contain a variable 'BPM0', which holds the ground-truth heart rate.\n",
    "        - All signals were sampled at 125 Hz.\n",
    "    - Short-comings of the dataset.\n",
    "        - The length of some \"REF_01_TYPE01\" files are not equal to the length of total 8 seconds frames in the \"DATA_01_TYPE01\" files. \n",
    "    \n",
    "    \n",
    "> - ### **Algorithhm Description**\n",
    ">   - #### **How the algorithm works**\n",
    ">        - The algorithm loads the database into two NumPy arrays. One for data and another for references.\n",
    ">        - For every file in the database, the data is divided into time frames. Every frame consists of 8 seconds.\n",
    ">        - These frames are stored in a NumPy array called features. \n",
    ">        - The true heartbeat rate for every frame is stored in a NumPy array called labels.\n",
    ">        - All feature signals are filtered by a bandpass filter (40:240) BPM.\n",
    ">        - The algorithm starts by converting the frame signal from the time domain to the frequency domain. \n",
    ">        - For every time window, FFT is used to calculate the spectrum of each channel of acceleration data and PPG signal, from which dominant frequencies are determined. \n",
    ">        - The dominant frequencies of the acceleration are the ones corresponding to the spectral peaks with an amplitude larger than 50% of the maximum amplitude in a given spectrum.\n",
    ">        - The dominant frequencies of the acceleration are removed from the PPG signal.\n",
    ">        - The dominant frequencies of the acceleration may have values that equal to the PPG dominant frequency. To prevent removing the dominant frequency of the PPG signal, the dominant frequency of the previous frame was used to remove any dominant acceleration frequencies that equal it (+- 12 BPM). \n",
    ">        - The heartbeat rate was obtained from the dominant frequency of the PPG signal\n",
    ">        - The algorithm contains a method for heartbeat rate verification. This method prevents a large change in the estimated BPM values in two successive time windows. The change of BPM values in two successive time windows was prevented to exceed 10 BPM.\n",
    ">   - #### **The specific aspects of the physiology of heartbeat rate**\n",
    "      - The heartbeat rate is always between 40:240 BPM, so a bandpass filter was used to remove frequencies out of this range. \n",
    ">        - The change of BPM values in two successive time windows rarely exceeds 10 BPM, so a heartbeat rate verification method was designed based on this concept.  \n",
    ">   - #### **Confidence rate**\n",
    "      - The energy concentration in the frequency spectrum around the estimated pulse rate is used to obtain a confidence rate for every estimate. This was done by summing frequency spectrum near the pulse rate estimate and dividing it by the sum of the entire spectrum. A high confidence rate means better estimations because it means that the signal has low noise, and there is one main dominant frequency in the signal.  \n",
    ">   - #### **Algorithm outputs** \n",
    ">     - The mean absolute error of the best 90% of heartbeat rate estimates for the entire dataset.\n",
    ">   - #### **caveats on algorithm outputs**\n",
    ">     - The algorithm generates output every 2 seconds. \n",
    ">   - #### **common failure modes**\n",
    ">     - The common failure takes place when the heartbeat of the first time frame was set wrong. This could happen if there is a strong acceleration signal in the first time frame. To avoid that, the subject is required to hold his hand for the first 8 seconds. \n",
    ">     - When there is no contact between the PPG sensor and the subject's skin.\n",
    "\n",
    ">- #### **Algorithm Performance**\n",
    "    - The mean absolute error (MAE) of the best 90 estimates was used to calculate the algorithm performance, and it was 6.7 through the entire dataset.\n",
    "    - The algorithm was tested on another dataset, and the (MAE) of the best 90 estimates was 6.83\n",
    "    - The energy concentration in the frequency spectrum around the estimated pulse rate is used to obtain a confidence rate for every estimate. This was done by summing frequency spectrum near the pulse rate estimate and dividing it by the sum of the entire spectrum.\n",
    "\n",
    "> -  ### Citations\n",
    ">       1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
